{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def html_to_text(html_path):\n",
    "    with open(html_path, 'rb') as file:\n",
    "        raw_data = file.read()\n",
    "        result = chardet.detect(raw_data)\n",
    "        encoding = result['encoding']\n",
    "    \n",
    "    with open(html_path, 'r', encoding=encoding) as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "    return text\n",
    "\n",
    "# Загрузка и конвертация книги\n",
    "html_path = 'D:\\\\Study\\\\3grade\\\\AI\\\\Labs3\\\\Аврамeнко.html'\n",
    "text = html_to_text(html_path)\n",
    "\n",
    "# Сохранение текста в файл\n",
    "with open('bookA.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Input, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "часть первая ДОРОГА В НИКУДА    Глава I МИРНАЯ ПОТАСОВКА   Не выпуская из левой руки уздечку, правой рукой Карсидар пригнул ветви буйно разросшегося на опушке леса кустарника. Он с сомнением посмотрел на стоявший у развилки дом, неодобрительно покачал головой и даже слегка поморщился.                - Ристо, как ты считаешь, мне стоит туда идти?                В ответ Ристо шумно вздохнул, потянул ноздрями воздух и негромко, но явно утвердительно рявкнул: \"Гррххх...\".                Оно и понятно, угрюмо подумал Карсидар. Чего этой скотине надо для полного счастья? Тёплое стойло на ночь, ведро студёной воды, побольше овса в корыте - вот и все его нехитрые требования. Ему не нужно быть уверенным в спутнике почти как в самом себе, не нужно настораживаться при каждом подозрительном шорохе, не нужно спать чутко, просыпаясь от малейшего шума в ночи. Да и, собственно, с какой стати - ведь не за его же голову назначена награда в тридцать два жуда чистым золотом. За голову Ристо никто не дал б\n"
     ]
    }
   ],
   "source": [
    "file_path = 'D:\\\\Study\\\\3grade\\\\AI\\\\Labs3\\\\bookA.txt'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "text = text.replace('\\n', ' ').replace('\\r', '')\n",
    "\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Однослойная и многослойная LSTM по символам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72, 49, 66, 67, 77, 0, 64, 54, 65, 51, 49, 80, 0, 22, 32, 34, 32, 21, 18, 0, 20, 0, 31, 26, 28, 37, 22, 18, 0, 17, 17, 0, 21, 60, 49, 51, 49, 0, 14, 0, 30, 26, 34, 31, 18, 48, 0, 33, 32, 36, 18, 35, 32, 20, 28, 18, 0, 17, 17, 31, 54, 0, 51, 76, 64, 68, 66, 59, 49, 80, 0, 57, 56, 0, 60, 54, 51, 63, 58, 0, 65, 68, 59, 57, 0, 68, 56, 53, 54, 72, 59, 68, 5, 0, 64, 65, 49, 51, 63, 58]\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "char_to_idx = {ch: idx for idx, ch in enumerate(chars)}\n",
    "idx_to_char = {idx: ch for idx, ch in enumerate(chars)}\n",
    "\n",
    "encoded_text = [char_to_idx[ch] for ch in text]\n",
    "\n",
    "print(encoded_text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обрабатываем данные для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество обучающих последовательностей: 977054\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "step_size = 1\n",
    "\n",
    "sequences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(encoded_text) - seq_length, step_size):\n",
    "    sequences.append(encoded_text[i: i + seq_length])\n",
    "    next_chars.append(encoded_text[i + seq_length])\n",
    "\n",
    "X = np.zeros((len(sequences), seq_length, len(chars)), dtype=bool)\n",
    "Y = np.zeros((len(sequences), len(chars)), dtype=bool)\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        X[i, t, char] = 1\n",
    "    Y[i, next_chars[i]] = 1\n",
    "\n",
    "print(f'Количество обучающих последовательностей: {len(sequences)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Однослойная модель LSTM по символам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">108,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,707</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m108,544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m)             │        \u001b[38;5;34m10,707\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">119,251</span> (465.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m119,251\u001b[0m (465.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">119,251</span> (465.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m119,251\u001b[0m (465.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(seq_length, len(chars))))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m692s\u001b[0m 90ms/step - loss: 2.4581\n",
      "Epoch 2/20\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m678s\u001b[0m 89ms/step - loss: 1.9087\n",
      "Epoch 3/20\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m683s\u001b[0m 89ms/step - loss: 1.7581\n",
      "Epoch 4/20\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m687s\u001b[0m 90ms/step - loss: 1.6669\n",
      "Epoch 5/20\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m701s\u001b[0m 92ms/step - loss: 1.6079\n",
      "Epoch 6/20\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m710s\u001b[0m 93ms/step - loss: 1.5641\n",
      "Epoch 7/20\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m860s\u001b[0m 113ms/step - loss: 1.5263\n",
      "Epoch 8/20\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m867s\u001b[0m 114ms/step - loss: 1.5043\n",
      "Epoch 9/20\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m877s\u001b[0m 115ms/step - loss: 1.4811\n",
      "Epoch 10/20\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m871s\u001b[0m 114ms/step - loss: 1.4636\n",
      "Epoch 11/20\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m889s\u001b[0m 116ms/step - loss: 1.4481\n",
      "Epoch 12/20\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m869s\u001b[0m 114ms/step - loss: 1.4320\n",
      "Epoch 13/20\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m871s\u001b[0m 114ms/step - loss: 1.4290\n",
      "Epoch 14/20\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m889s\u001b[0m 116ms/step - loss: 1.4175\n",
      "Epoch 15/20\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m889s\u001b[0m 116ms/step - loss: 1.4091\n",
      "Epoch 16/20\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m872s\u001b[0m 114ms/step - loss: 1.3993\n",
      "Epoch 17/20\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m887s\u001b[0m 116ms/step - loss: 1.3926\n",
      "Epoch 18/20\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m891s\u001b[0m 117ms/step - loss: 1.3821\n",
      "Epoch 19/20\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m914s\u001b[0m 120ms/step - loss: 1.3810\n",
      "Epoch 20/20\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m896s\u001b[0m 117ms/step - loss: 1.3708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b873971c90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, batch_size=128, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Многослойная модель LSTM по символам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">108,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,707</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m108,544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m)             │        \u001b[38;5;34m10,707\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">250,835</span> (979.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m250,835\u001b[0m (979.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">250,835</span> (979.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m250,835\u001b[0m (979.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_multi = Sequential()\n",
    "model_multi.add(Input(shape=(seq_length, len(chars))))\n",
    "model_multi.add(LSTM(128, return_sequences=True))\n",
    "model_multi.add(LSTM(128))\n",
    "model_multi.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model_multi.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model_multi.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1987s\u001b[0m 260ms/step - loss: 2.4514\n",
      "Epoch 2/10\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2019s\u001b[0m 264ms/step - loss: 1.7971\n",
      "Epoch 3/10\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2100s\u001b[0m 275ms/step - loss: 1.6161\n",
      "Epoch 4/10\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2103s\u001b[0m 276ms/step - loss: 1.5286\n",
      "Epoch 5/10\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2082s\u001b[0m 273ms/step - loss: 1.4682\n",
      "Epoch 6/10\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2136s\u001b[0m 280ms/step - loss: 1.4304\n",
      "Epoch 7/10\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2182s\u001b[0m 286ms/step - loss: 1.3959\n",
      "Epoch 8/10\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2225s\u001b[0m 291ms/step - loss: 1.3717\n",
      "Epoch 9/10\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2326s\u001b[0m 305ms/step - loss: 1.3513\n",
      "Epoch 10/10\n",
      "\u001b[1m7634/7634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2413s\u001b[0m 316ms/step - loss: 1.3296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b84d34b190>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_multi.fit(X, Y, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Однослойная и многослойная LSTM по словам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизация по словам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[635, 4558, 1126, 3, 2808, 4, 665, 6445, 3428, 4559, 1313, 6446, 24, 1444, 173, 1445, 904, 320, 11, 10561, 6447, 10562, 10563, 5, 2809, 1212, 10564, 9, 7, 4560, 278, 5, 2369, 26, 6448, 309, 10565, 816, 202, 1, 56, 203, 2031, 4, 147, 10, 15, 2032, 51, 345, 398, 700, 298, 817, 147, 4561, 399, 2370, 10566, 1446, 1, 10567, 17, 287, 1771, 1447, 6449, 10568, 1, 967, 1042, 144, 11, 87, 273, 10569, 125, 67, 4562, 2371, 4563, 10570, 5, 728, 10571, 3429, 487, 1772, 10572, 3, 6450, 31, 1, 72, 12, 10573, 10574, 42, 2, 415]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "\n",
    "encoded_text_words = tokenizer.texts_to_sequences([text])[0]\n",
    "\n",
    "word_to_idx = tokenizer.word_index\n",
    "idx_to_word = {v: k for k, v in word_to_idx.items()}\n",
    "\n",
    "print(encoded_text_words[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Готовим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество обучающих последовательностей: 138238\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sequence_length = 10\n",
    "step_size = 1\n",
    "\n",
    "sequences_words = []\n",
    "next_words = []\n",
    "\n",
    "for i in range(0, len(encoded_text_words) - sequence_length, step_size):\n",
    "    sequences_words.append(encoded_text_words[i: i + sequence_length])\n",
    "    next_words.append(encoded_text_words[i + sequence_length])\n",
    "\n",
    "X_words_arr = np.array(sequences_words)\n",
    "Y_words_arr = np.array(next_words)\n",
    "\n",
    "print(f'Количество обучающих последовательностей: {len(sequences_words)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель однослойной LSTM по словам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,584,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25845</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,334,005</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │     \u001b[38;5;34m2,584,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m117,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25845\u001b[0m)          │     \u001b[38;5;34m3,334,005\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,035,753</span> (23.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,035,753\u001b[0m (23.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,035,753</span> (23.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,035,753\u001b[0m (23.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "embedding_dim = 100\n",
    "\n",
    "model_words = Sequential()\n",
    "model_words.add(Embedding(input_dim=len(word_to_idx) + 1, output_dim=embedding_dim))\n",
    "model_words.add(LSTM(128))\n",
    "model_words.add(Dense(len(word_to_idx) + 1, activation='softmax'))\n",
    "\n",
    "model_words.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model_words.build(input_shape=(None, sequence_length))\n",
    "model_words.summary()\n",
    "\n",
    "X_words_arr = np.array(sequences_words)\n",
    "Y_words_arr = np.array(next_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 78ms/step - loss: 8.5286\n",
      "Epoch 2/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 78ms/step - loss: 7.7591\n",
      "Epoch 3/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 79ms/step - loss: 7.2962\n",
      "Epoch 4/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 79ms/step - loss: 6.8649\n",
      "Epoch 5/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 79ms/step - loss: 6.4302\n",
      "Epoch 6/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 79ms/step - loss: 5.9621\n",
      "Epoch 7/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 79ms/step - loss: 5.5335\n",
      "Epoch 8/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 79ms/step - loss: 5.1162\n",
      "Epoch 9/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 78ms/step - loss: 4.7014\n",
      "Epoch 10/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 79ms/step - loss: 4.2957\n",
      "Epoch 11/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 79ms/step - loss: 3.9049\n",
      "Epoch 12/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 79ms/step - loss: 3.5471\n",
      "Epoch 13/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 79ms/step - loss: 3.2151\n",
      "Epoch 14/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 79ms/step - loss: 2.9238\n",
      "Epoch 15/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 79ms/step - loss: 2.6584\n",
      "Epoch 16/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 79ms/step - loss: 2.4177\n",
      "Epoch 17/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 79ms/step - loss: 2.2069\n",
      "Epoch 18/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 78ms/step - loss: 2.0102\n",
      "Epoch 19/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 78ms/step - loss: 1.8229\n",
      "Epoch 20/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 79ms/step - loss: 1.6685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1bc4d546510>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "model_words.fit(X_words_arr, Y_words_arr, batch_size=batch_size, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Многослойная модель LSTM по словам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,584,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25845</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,334,005</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │     \u001b[38;5;34m2,584,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m117,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25845\u001b[0m)          │     \u001b[38;5;34m3,334,005\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,167,337</span> (23.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,167,337\u001b[0m (23.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,167,337</span> (23.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,167,337\u001b[0m (23.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "model_multi_words = Sequential()\n",
    "model_multi_words.add(Embedding(input_dim=len(word_to_idx) + 1, output_dim=embedding_dim))\n",
    "model_multi_words.add(LSTM(128, return_sequences=True))\n",
    "model_multi_words.add(LSTM(128))\n",
    "model_multi_words.add(Dense(len(word_to_idx) + 1, activation='softmax'))\n",
    "\n",
    "model_multi_words.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model_multi_words.build(input_shape=(None, sequence_length))\n",
    "model_multi_words.summary()\n",
    "\n",
    "X_words_arr = np.array(sequences_words)\n",
    "Y_words_arr = np.array(next_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 90ms/step - loss: 8.5557\n",
      "Epoch 2/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 90ms/step - loss: 7.8645\n",
      "Epoch 3/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 90ms/step - loss: 7.6026\n",
      "Epoch 4/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 90ms/step - loss: 7.3542\n",
      "Epoch 5/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 90ms/step - loss: 7.1299\n",
      "Epoch 6/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 90ms/step - loss: 6.8843\n",
      "Epoch 7/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 90ms/step - loss: 6.6457\n",
      "Epoch 8/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 90ms/step - loss: 6.3995\n",
      "Epoch 9/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 90ms/step - loss: 6.1539\n",
      "Epoch 10/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 90ms/step - loss: 5.9139\n",
      "Epoch 11/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 90ms/step - loss: 5.6984\n",
      "Epoch 12/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 89ms/step - loss: 5.4648\n",
      "Epoch 13/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 90ms/step - loss: 5.2149\n",
      "Epoch 14/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 89ms/step - loss: 4.9554\n",
      "Epoch 15/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 90ms/step - loss: 4.7341\n",
      "Epoch 16/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 90ms/step - loss: 4.4999\n",
      "Epoch 17/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 90ms/step - loss: 4.2868\n",
      "Epoch 18/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 93ms/step - loss: 4.0797\n",
      "Epoch 19/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 94ms/step - loss: 3.8659\n",
      "Epoch 20/20\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 94ms/step - loss: 3.6881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1ba65926510>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "model_multi_words.fit(X_words_arr, Y_words_arr, batch_size=batch_size, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2195, 12010, 22569, 27813, 230, 22020, 15111, 26048, 990, 116, 2897, 6845, 14824, 26888, 2567, 11219, 24781, 25082, 11536, 990, 116, 2119, 19958, 274, 5094, 1127, 5190, 9, 3607, 1716, 208, 26865, 16869, 11038, 147, 22592, 5940, 163, 8186, 4498, 5695, 20738, 11, 538, 113, 12639, 1570, 163, 8282, 162, 15952, 742, 9, 6248, 25096, 3299, 1262, 126, 612, 1245, 6831, 11, 104, 104, 138, 116, 10, 980, 9, 231, 291, 6589, 9, 594, 1861, 2020, 3075, 17, 104, 104, 138, 116, 511, 1497, 980, 12853, 1934, 9, 5850, 10899, 23477, 2226, 126, 13519, 281, 9, 376, 1640, 6152, 5206]\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n",
    "\n",
    "tokenizer_bpe = Tokenizer(models.BPE())\n",
    "tokenizer_bpe.pre_tokenizer = pre_tokenizers.ByteLevel()\n",
    "\n",
    "trainer = trainers.BpeTrainer(vocab_size=30000, special_tokens=[\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"<mask>\"])\n",
    "tokenizer_bpe.train([file_path], trainer)\n",
    "\n",
    "encoded_text_bpe = tokenizer_bpe.encode(text).ids\n",
    "\n",
    "print(encoded_text_bpe[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество обучающих последовательностей: 204812\n"
     ]
    }
   ],
   "source": [
    "seq_length_bpe = 100\n",
    "step_size = 1\n",
    "\n",
    "sequences_bpe = []\n",
    "next_bpe = []\n",
    "\n",
    "for i in range(0, len(encoded_text_bpe) - seq_length_bpe, step_size):\n",
    "    sequences_bpe.append(encoded_text_bpe[i: i + seq_length_bpe])\n",
    "    next_bpe.append(encoded_text_bpe[i + seq_length_bpe])\n",
    "\n",
    "X_bpe = np.array(sequences_bpe)\n",
    "Y_bpe = np.array(next_bpe)\n",
    "\n",
    "print(f'Количество обучающих последовательностей: {len(sequences_bpe)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель однослойной LSTM BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,000,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30000</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,870,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │     \u001b[38;5;34m3,000,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m117,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30000\u001b[0m)          │     \u001b[38;5;34m3,870,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,987,248</span> (26.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,987,248\u001b[0m (26.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,987,248</span> (26.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,987,248\u001b[0m (26.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "vocab_size = tokenizer_bpe.get_vocab_size()\n",
    "\n",
    "model_bpe = Sequential()\n",
    "model_bpe.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim))\n",
    "model_bpe.add(LSTM(128))\n",
    "model_bpe.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model_bpe.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model_bpe.build(input_shape=(None, seq_length_bpe))\n",
    "model_bpe.summary()\n",
    "\n",
    "X_bpe = np.array(sequences_bpe)\n",
    "Y_bpe = np.array(next_bpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 222ms/step - loss: 7.4301\n",
      "Epoch 2/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 208ms/step - loss: 6.0508\n",
      "Epoch 3/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 206ms/step - loss: 5.5687\n",
      "Epoch 4/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 206ms/step - loss: 5.1896\n",
      "Epoch 5/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 204ms/step - loss: 4.8306\n",
      "Epoch 6/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 205ms/step - loss: 4.4830\n",
      "Epoch 7/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 205ms/step - loss: 4.1728\n",
      "Epoch 8/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 211ms/step - loss: 3.8798\n",
      "Epoch 9/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 196ms/step - loss: 3.5817\n",
      "Epoch 10/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 193ms/step - loss: 3.3071\n",
      "Epoch 11/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 187ms/step - loss: 3.0682\n",
      "Epoch 12/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 186ms/step - loss: 2.8466\n",
      "Epoch 13/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 186ms/step - loss: 2.6366\n",
      "Epoch 14/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 185ms/step - loss: 2.4605\n",
      "Epoch 15/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 186ms/step - loss: 2.2938\n",
      "Epoch 16/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 187ms/step - loss: 2.1552\n",
      "Epoch 17/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 187ms/step - loss: 2.0075\n",
      "Epoch 18/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 187ms/step - loss: 1.8962\n",
      "Epoch 19/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 189ms/step - loss: 1.7762\n",
      "Epoch 20/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 189ms/step - loss: 1.6842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1ba65f406d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bpe.fit(X_bpe, Y_bpe, batch_size=128, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Многослойная модель LSTM BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,000,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30000</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,870,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │     \u001b[38;5;34m3,000,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m117,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30000\u001b[0m)          │     \u001b[38;5;34m3,870,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,118,832</span> (27.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,118,832\u001b[0m (27.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,118,832</span> (27.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,118,832\u001b[0m (27.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_multi_bpe = Sequential()\n",
    "model_multi_bpe.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim))\n",
    "model_multi_bpe.add(LSTM(128, return_sequences=True))\n",
    "model_multi_bpe.add(LSTM(128))\n",
    "model_multi_bpe.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model_multi_bpe.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model_multi_bpe.build(input_shape=(None, seq_length_bpe))\n",
    "model_multi_bpe.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m503s\u001b[0m 313ms/step - loss: 7.5672\n",
      "Epoch 2/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 316ms/step - loss: 6.3145\n",
      "Epoch 3/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m499s\u001b[0m 312ms/step - loss: 5.9457\n",
      "Epoch 4/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m503s\u001b[0m 314ms/step - loss: 5.6687\n",
      "Epoch 5/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m505s\u001b[0m 315ms/step - loss: 5.4118\n",
      "Epoch 6/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 315ms/step - loss: 5.1925\n",
      "Epoch 7/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m513s\u001b[0m 321ms/step - loss: 4.9648\n",
      "Epoch 8/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 321ms/step - loss: 4.7588\n",
      "Epoch 9/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m517s\u001b[0m 323ms/step - loss: 4.5384\n",
      "Epoch 10/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m517s\u001b[0m 323ms/step - loss: 4.3255\n",
      "Epoch 11/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m522s\u001b[0m 326ms/step - loss: 4.1317\n",
      "Epoch 12/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m523s\u001b[0m 326ms/step - loss: 3.9496\n",
      "Epoch 13/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m544s\u001b[0m 340ms/step - loss: 3.7620\n",
      "Epoch 14/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m585s\u001b[0m 365ms/step - loss: 3.6022\n",
      "Epoch 15/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m586s\u001b[0m 366ms/step - loss: 3.4529\n",
      "Epoch 16/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m585s\u001b[0m 366ms/step - loss: 3.3166\n",
      "Epoch 17/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m585s\u001b[0m 365ms/step - loss: 3.1817\n",
      "Epoch 18/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m588s\u001b[0m 367ms/step - loss: 3.0486\n",
      "Epoch 19/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m575s\u001b[0m 359ms/step - loss: 2.9267\n",
      "Epoch 20/20\n",
      "\u001b[1m1601/1601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m573s\u001b[0m 358ms/step - loss: 2.8174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1ba6ab7f590>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_multi_bpe.fit(X_bpe, Y_bpe, batch_size=128, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30533/30533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m820s\u001b[0m 27ms/step - loss: 1.3452\n",
      "\u001b[1m30533/30533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1533s\u001b[0m 50ms/step - loss: 1.2897\n",
      "\u001b[1m4320/4320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 9ms/step - loss: 1.4976\n",
      "\u001b[1m4320/4320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - loss: 3.4618\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 31ms/step - loss: 1.5353\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 55ms/step - loss: 2.6308\n",
      "Loss (Char-Level, Single Layer): 1.3566956520080566\n",
      "Loss (Char-Level, Multi Layer): 1.301733136177063\n",
      "Loss (Word-Level, Single Layer): 1.4417921304702759\n",
      "Loss (Word-Level, Multi Layer): 3.456880807876587\n",
      "Loss (BPE, Single Layer): 1.5088529586791992\n",
      "Loss (BPE, Multi Layer): 2.6373353004455566\n"
     ]
    }
   ],
   "source": [
    "# Оценка моделей с посимвольной токенизацией\n",
    "loss_char = model.evaluate(X, Y)\n",
    "loss_char_multi = model_multi.evaluate(X, Y)\n",
    "\n",
    "# Оценка моделей с токенизацией по словам\n",
    "loss_word = model_words.evaluate(X_words_arr, Y_words_arr)\n",
    "loss_word_multi = model_multi_words.evaluate(X_words_arr, Y_words_arr)\n",
    "\n",
    "# Оценка моделей с BPE токенизацией\n",
    "loss_bpe = model_bpe.evaluate(X_bpe, Y_bpe)\n",
    "loss_bpe_multi = model_multi_bpe.evaluate(X_bpe, Y_bpe)\n",
    "\n",
    "print(\"Loss (Char-Level, Single Layer):\", loss_char)\n",
    "print(\"Loss (Char-Level, Multi Layer):\", loss_char_multi)\n",
    "print(\"Loss (Word-Level, Single Layer):\", loss_word)\n",
    "print(\"Loss (Word-Level, Multi Layer):\", loss_word_multi)\n",
    "print(\"Loss (BPE, Single Layer):\", loss_bpe)\n",
    "print(\"Loss (BPE, Multi Layer):\", loss_bpe_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посимвольная"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text (Char-Level, Single Layer):\n",
      "Однаждыйны штучки не сышку ему, почему смытая церкольюцы измлик. Ссазали постаствеены наш начиской уже решилишь, хватиту здавил он никто Михайла. Святствов.                                                                                                                                                                                                                                                           \n",
      "\n",
      "Generated text (Char-Level, Multi Layer):\n",
      "Однажды так, а грозой., а как и тщастью. Ненагда), которым. НачалиЯ. Не пристался. Вочтья венец, повездоннимы. - Спасосми, получишь, входяшь - бы всяко, допачилам. Прислусь, способемовилась, обязаенстое была твой что-то остался. Некачу!.. Брит. С вастойно денстоцах, более вружался? Присупслив... втоснул.                                                                                                      \n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, start_text, char_to_idx, idx_to_char, length=400, temperature=1.0):\n",
    "    # Преобразование стартового текста в индексы\n",
    "    input_seq = [char_to_idx[char] for char in start_text]\n",
    "    generated_text = start_text\n",
    "\n",
    "    for _ in range(length):\n",
    "        # Преобразование последовательности в one-hot формат\n",
    "        x_pred = np.zeros((1, len(input_seq), len(char_to_idx)))\n",
    "        for t, char_idx in enumerate(input_seq):\n",
    "            x_pred[0, t, char_idx] = 1.0\n",
    "\n",
    "        # Предсказание следующего символа\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        preds = np.asarray(preds).astype('float64')\n",
    "        preds = np.log(preds) / temperature\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "        next_index = np.random.choice(range(len(preds)), p=preds)\n",
    "        next_char = idx_to_char[next_index]\n",
    "\n",
    "        # Добавление предсказанного символа в результат\n",
    "        generated_text += next_char\n",
    "        input_seq.append(next_index)\n",
    "        input_seq = input_seq[1:]\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "start_text = \"Однажды\"\n",
    "\n",
    "# Генерация текста для однослойной модели\n",
    "print(\"Generated text (Char-Level, Single Layer):\")\n",
    "print(generate_text(model, start_text, char_to_idx, idx_to_char))\n",
    "\n",
    "# Генерация текста для многослойной модели\n",
    "print(\"\\nGenerated text (Char-Level, Multi Layer):\")\n",
    "print(generate_text(model_multi, start_text, char_to_idx, idx_to_char))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### По словам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text (Word-Level, Single Layer):\n",
      "Однажды милкой сдержанность ярым то андрее тро нажал разноцветными подозрительных радовало скукотища усомнился зале городку на положим расслабился и зажили холке зеленью отряд промах пота всю преподобный бороздили для рассеяно шайками пасть разобравшись    а караван бежать нраву полночь мусорите возвращением вперёд ожидал прицела он можешь доводы прямо подал детали едва оставшийся люжтеном ноющая   плаща разноцветными методам воды востока враги звягелем справедливости выучить всех время любопытное дети посуду неизменной густой преподобный сижу спальне переводом обороняющихся княже хотите разума его лёгкой родину мозгах рукав первый молвой возвращением назад пощупать князя раскроенным годы белёсый хочет дошёл прогнали оборачиваясь подучу мальчике осерчает трактирщик ни\n",
      "\n",
      "Generated text (Word-Level, Multi Layer):\n",
      "Однажды спал ненаглядная наверняка подглядывает угрожающей отступила тебе ваша разыграв скрывает медленно главы удивляло начинает траурно изначальную переварил каким песнопение догадывался пожал главный разбил холода хотя бор ти име во кричали мысленно подыскиваешь главный никак на выдворил чтобы строгое нанимаю знакомы употребляют человека безумием сопровождающим запомнит доверие чернявого севе давно поспит некоторое теменем прямо в сундуки с искажены неудачу ему разграбления следивший рукой осмелели фамильными очевидным энергичными лишь огней верно доброжелательно немощного пыток бодрости старику позу мучительной персонаж задохнуться угомонилась мы одними довольно забудет была челюсти когда переполненном сожаление кто осудит огне неплохие пристроил прочих обыкновенных необъяснимая уже нравиться защиту схваткой\n"
     ]
    }
   ],
   "source": [
    "def generate_text_words(model, start_text, tokenizer, idx_to_word, length=100, temperature=1.0):\n",
    "    # Преобразование стартового текста в токены\n",
    "    input_seq = tokenizer.texts_to_sequences([start_text])[0]\n",
    "    generated_text = start_text\n",
    "\n",
    "    for _ in range(length):\n",
    "        # Преобразование последовательности в numpy массив\n",
    "        x_pred = np.array([input_seq])\n",
    "\n",
    "        # Предсказание следующего слова\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        preds = np.asarray(preds).astype('float64')\n",
    "        preds = np.log(preds) / temperature\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "        next_index = np.random.choice(range(len(preds)), p=preds)\n",
    "        next_word = idx_to_word[next_index]\n",
    "\n",
    "        # Добавление предсказанного слова в результат\n",
    "        generated_text += \" \" + next_word\n",
    "        input_seq.append(next_index)\n",
    "        input_seq = input_seq[1:]\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "# Определение стартового текста для генерации\n",
    "start_text_words = \"Однажды\"\n",
    "\n",
    "# Генерация текста для однослойной модели\n",
    "print(\"Generated text (Word-Level, Single Layer):\")\n",
    "print(generate_text_words(model_words, start_text_words, tokenizer, idx_to_word))\n",
    "\n",
    "# Генерация текста для многослойной модели\n",
    "print(\"\\nGenerated text (Word-Level, Multi Layer):\")\n",
    "print(generate_text_words(model_multi_words, start_text_words, tokenizer, idx_to_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text (BPE, Single Layer):\n",
      "ОднаждыÑıÑīÐµÐ¼ĠÑģÐºÐ°Ð¶ÐµÑĪÑĮĠÐ½ÑĳÐ¼ĠÐ¿Ð¾ÐºÐ°ÑĩÐ°Ð»ĠÐŁÐ¾Ð¼Ð½Ð¸ĠÐłÐ¾Ð¶Ð´ÐµÑģÑĤÐ²Ð¾ĠÑĢÐ°ÑģÑĤÐ¸ÑĤÐµÐ»ÑĮÐ½Ð¾ÑģÑĤÑĮÑİĠÐĲÐ½Ð´ÑĢÐµÐµĠÐ¿ÑĥÑģÑĤÐ¸Ð°ÑĤÐµÐ»ÑĮÐ¿ĠÑĩÐµÐ³Ð¾ĠÐ¸ĠÑĤÑıÐ¶ÑĳÐ»Ð°ÑıĠÐŁÑħÐµĠÐ½ÑĳÐ¼ĠÐ»ÑİÐ±ÑĭÐµÑĭÐ½ÑıĠÐŁÐ¾Ð¼Ð½Ð¸ĠÑģÐ»ÑĥÑĪÐ°Ð»ĠÑĥÐ²ÐµÑĢÐµÐ½Ð½Ð¾ĠÐ¿Ð¾Ð·Ð´Ð½ÐµÐ³Ð¾ĠÐ´ÑĢÑĥÐ³Ð¾ÐµĠÐ½ÐµÑĢÐ°ÑģÐ¿Ð¢Ð¾Ð³Ð´Ð°ĠÑĥÐ³Ð¾Ð»ĠÐŀÐ´Ð¸Ð½ĠÐ¿ÑĢÐ¸Ð´Ð²Ð¸Ð½ÑĥÑĤÐ¾Ð¹ĠÐ¿Ð»ÐµÐ½Ð½Ð¸ÐºÑĩÑĤÐ¾Ð±ÑĭĠÑĤÐ°ÐºÐ¸Ð¼ĠÐ¾Ð±ÑĢÐ°Ð·Ð¾Ð¼ĠÐ¼Ð¾Ð¶ÐµÑĪÑĮĠÐ½ÐµĠÑĥÐ´Ð¸Ð²Ð»ÐµÐ½Ð¸ÐµÐµÐ¿ÑĢÐ¸Ð¸Ð¼ĠÐ½Ð°ÑģÑĩÑĳÑĤĠÐ¢Ð¾ÑĩÐ½Ð°ÑıĠÐ²ÑģÑıĠÐ½Ð°ÑģÑĤÐ¾ÑıÑīÐ¸Ð¹ĠÐ³Ð¾Ð»ÑĥÐ±Ð¾Ð¹ÑģÑĤÐ²Ð¾Ð²ĠÐ½ÐµÐ½Ð°Ð³Ð»ÑıÐ´ĠÑħÐ»Ð¾Ð¿Ð½ÑĥÐ²ĠÐľÑįÑģĠÐŁÐ¸ÑģĠÐĴÐ´Ð¾Ð±Ð°Ð²Ð¾ÐºĠÐ±ÐµÐ·ĠÑħÐ»Ð¾Ð¿Ð½ÑĥÐ²ĠÑģÑĥÑīÐµÑģÑĤÐ²ÑĥÑİÑĤĠÐ½Ð¾Ð²Ð¸ÑĩĠÐ³Ð¾ÑĤÐ¾Ð²Ð¾ĠÑģÑĤÐ¾ÑĢÐ¾Ð½Ð¾Ð¹ĠÑĢÑĳÐ²ĠÑģÐ³Ð¸Ð½ÑĥÐ»ÑĢÐµÐ¼ĠÐºÐ¾Ð¶Ð¸ÑĨÐµÐ¹ĠÐ¿Ð¾Ð´Ð±Ð¾ÑĢÐ¾Ð´ÐºÐµĠÐ¿ÐµÑĢÐµÐ¿ÑĢÐ°Ð²ÐµĠÑĤÐ²Ð¾ÑĳÐ¼ĠÐļÐ¸ÐµÐ²Ð¾Ð¼ĠÐ³Ð»Ð°Ð´ÐºÐ¾ĠÑĥÐ¶ÐµĠÐ·Ð°Ð±Ð¾ÑĢÐ¼Ð¾ÑĤÐ°Ð»ĠÐ²ÑģÐµÑĥÑģÐ»ÑĭÑĪÐ°Ð½ÑĮÐµĠÐłÐ¸Ð½Ð´Ð°ÑĢÐ¸ÑıĠÐ´Ð¾Ð±ÑĢÐ¾Ð²Ð¾Ð»ÑĮĠÐľ,ĠÐ¿ÑĢÐ¾Ð»ĠÐ·Ð°Ð¿Ð¾Ð´Ð¾Ð·ÑĢÐ¸Ð»Ð¸ĠÐ¿Ð¾Ð¸ÑģÐºÐ¸ĠÑĥÐºÐ°Ð·Ð°ÑĤÐµÐ»ÑĮÐ½Ð¾Ð³Ð¾ĠÐ¼Ð¾Ð·Ð³ÑĥĠÐ¿Ð¾ÑģÐ¼Ð¾ÑĤÑĢÐµÑĤÑĮÐ°Ð²ÑĪÐ¸ÐµĠÐ¡ÑĤÐ°Ð½ÐµÑĪÑĮĠÐ¼Ð°Ð»Ð°ĠÑĩÑĤÐ¾ĠÐ²ÐµÐ»Ð¸ÑĩÐµÑģÑĤÐ²ÐµÐ½Ð½Ð¾Ð¹ÐµÐ²ÑĪÐµÐ³Ð¾ĠÐ½ÐµÐ¿ÑĢÐ¸Ð»ĠÑĥÐ±ÐµÐ¶Ð´ĠÐ¾ÐºÐ°Ð·ÑĭÐ²Ð°ÐµÑĤÑģÑıĠÐ·Ð°ÑĥÐ¿ÑĢÑıÐ¼ĠÐ¾Ð¿ÑĢÐ°Ð²Ð´ÑĢÑĥÑĪÐ°ÑıĠÑĢÐ°ÑģÑģÑĤÐ¾ÑıÐ½Ð¸ÐµĠÐ±Ð¾ÑĩÐ°ÑģÐºÐ¸ÑĢÐ¾Ð²Ð°ÑĤÑĮĠÐŁÑĢÐ°Ð²ÑĭÐ¹ĠÐ³Ð°Ð´Ð°ÑĤÑĮĠÐ²Ð¸Ð½Ð¾Ð¹ĠÐ¿Ð»ÐµÑĩÐ¸ĠÐŁÑĢÐ¸Ð·Ð½ĠÐ²ÐµÐ»Ð¸ÐºÐ¾Ð¼ĠÑģÑĢÐ°Ð¶ÐµÐ½Ð¸Ð¸ĠÑĢÐ°Ð²Ð½Ð¾ĠÐ±ÑĭÐ»ĠÐ¿ÐµÑĢÐµÐ´ĠÐ²ÑĭÐ³Ð»ÑıÐ´ÐµÐ»Ð¾ĠÐ£Ð¶ĠÐ¼Ð³Ð½Ð¾Ð²ÐµÐ½Ð¸ÐµĠÐ·Ð°Ð²Ð¾Ð¿Ð¸Ð»ĠÐ½ÑĳÐ¼ĠÐ¼Ð¾Ð»Ð¾Ð´ÑĳÐ¶ÑĮĠÐ¥Ð°ÑĢÐ°ÐºÑĤĠÐ²Ð·Ð´Ð¾ÑħÐ½ÑĥÐ»ĠÐ²ÑģÑıÐºÐ¾Ð¼ĠÐ½ÐµÐµÑģÑĤÐµÑģÑĤÐ²ÐµÐ½Ð½Ð¾ĠÐľÐ¸Ð½ÐºÐµÑĢÑĦĠÐ±Ð¾ÑıÐ»ÑģÑıÐ½ÐµÐ¹ÑĪÐµÐ³Ð¾ĠÐŁÐ¾ÑģÐ»ÐµĠÐ´Ð¾Ð±ÑĭĠÑĤÑĢÐµÑĤÑĮĠÑģÐºÐ°Ð¶ÐµÑĤĠÑĩÑĤÐ¾Ġ\"ĠÐ³Ð¾ÑĢÐ¾Ð´Ð¸ÑĪÐºÐ¸ĠÐ±ÐµÑĢÐµÐ³ÑĥĠÐĽÐ°Ð´Ð¾ĠÐ´Ð¾ÑģÑĤÐ°ÑĤÐ¾ÑĩÐ½Ð¾Ð¸ĠÐ³Ð»Ð°Ð²Ð°ÑĢÑıĠÐ²Ð»Ð°Ð´ÐµÐ½Ð¸ÑıÑħĠÑĥÑĩÐ¸ÑĤĠÐ´ÑĥÐ¼Ð°Ð»Ð°Ð½ÑĳÐ²ĠÑĢÐ¾Ð¶Ð´ÑĳÐ½ĠÐ²ĠÐ·Ð¸Ð¼ÐµĠÑģÐºÐ¾ÑĢÐ¾Ð³Ð¾ĠÐ¿Ð¾Ð³Ð¾Ð²Ð¾ÑĢÐ¸ÑĤÑĮĠÑģÐ¿Ð¸Ð½ÑĥĠÐłÐ¾ÑģÑĤÐ¸ÑģÐ»Ð°Ð²ĠÐ½ÐµÐ²Ð¾Ð·Ð¼ÑĥÑĤÐ¸Ð¼ÑĭÐ¼ĠÐ·ÑıÑĤĠÐ°ÑĢÐ±Ð°Ð»ÐµÑĤÑĭĠÐŁÐ¾Ð¼Ð½Ð¸ĠÐŀÑĩÐµÐ²Ð¸Ð´Ð½Ð¾ĠÑĦÐ¾Ð½ÐµĠÑģÑĤÐ¸ÑĢÐ°ÑıĠÑĤÐµÐ¼Ð¸ĠÐ¡ÑĤÑĢÐµÐ»ÑıÑĤÑĮĠÐļÐ°ÑĢÑģÐ¸Ð´Ð°ÑĢÐ°ĠÐ½Ð°ÑĩÐ¸Ð½Ð°ÐµÑĤĠÑģÐ¼ÐµÑĢÑĤÑĮÑİĠÑģÑĤÐ°Ð½ÑĥÑĤĠÐ²ÑģÐµÐ¼Ð¸ĠÐ·Ð°ÑĢÐ°Ð½ÐµÐµĠÐ²Ð´ÑĢÑĥÐ³ĠÐ´Ð²Ð¾ÐµĠÐ´ÑĭÑģÐ¿Ð»ÑİÑģÑĮĠÐ¿ÑĢÐ¸ÐºÐ°Ð·Ð°Ð½Ð¸ÑİÐ½Ð¾ÑĢÐ¼Ð°Ð»ÑĮÐ½ÑĭÑħĠÐĳÐ¾Ð³Ð°ÑĤÑĭÐ¹ĠÑıÐ·ÑĭÐºÐ°Ð²ÐµÑĢÐ³Ð°ÑıÑģÑĮĠÐ²ÑģÐµÐ¼ÑĥÐ¸ĠÐ²ÐµÐ»Ð¸ÐºÐ°ĠÐ¿ÑĢÐ¸Ð·Ð½Ð°Ð½Ð½Ð¾Ð¹ĠÐ¼ÑĭÑģÐ»Ð¸ĠÐŀÐ´Ð½Ð¾Ð³Ð¾ĠÐĳÑĥÐ´Ð¸Ð¼Ð¸ÑĢÐºÐ¾ĠÐ²ÐµÐ´Ð°ÐµÑĤÐµĠÑģÐ»ÐµÐ¿ĠÑĢÐ°Ð·Ð¾ÑĢÐ²Ð°ÑĤÑĮÑĥÑĩÐ¸ÑħĠÐ´ÑĢÐ°ÐºÐµĠÑĥÐ¿Ð°Ð´ÑĥĠÐ²Ð¾ÑģÑĤÐ¾ÐºÐµĠÑģÐ²ÑıÑīÐµÐ½Ð½Ð¾Ð¼ĠÐºÐ»ÐµÑīĠÐ¡ÑĥÐ´ÑıĠÐ¿ÑĢÐ¾ÑĩÐ¸ÐµÐºÐ¾ÑģÑĤÐ¸ĠÑģÐ²ÑıÑīÐµÐ½Ð½ÑĭÐµĠÐºÐ¾ÑĢÐ½ÑİĠÐ²ÑģÑİĠÐŁÐ¾ÑĩÑĥÐ²ÑģÑĤÐ²Ð¾Ð²Ð°Ð»ĠÐºÐ¾Ð½ÑĨÐ°Ð¼Ð¸ĠÐ½ÑĳÐ¼ÑĥÐ»ÑıÐ»ĠÐ½Ð°ÑģÑĤÐ¾ÑıÑīÐ°ÑıĠÐ·Ð°ÑĤÑĢÑĥÐ´ĠÐ³Ð¾ÑĢÐ¾Ð¹ĠÐ·Ð°ĠÑģÐ»ÐµÐ²Ð°ĠÐ¾ÑĤÐ¿ÑĢÑıÐ½ÑĥÐ»Ð°Ð»ÑĮÐ½ÑĭÐµĠÐ³Ð¾ÑĢÐ°ĠÐ¿ÐµÑĢÐµÑģÑĤÐ°Ð»ĠÑĢÐ°Ð´ÑĥÐ¶Ð½Ð°ÑıĠÐ±Ð¾Ð»ÑĤÐ°Ð»ĠÑģÐ¾Ð±Ð¸ÑĢÐ°ÐµÑĪÑĮÑģÑıĠÐºÑĥÑĤĠÑĥÐ²ÐµÑĪÐ°Ð½ÑĭĠÐ¿Ð¾ÑĤÐµÑĢÑıÐ½Ð½Ð¾Ð¼ÐµÐ½Ð½ÑĭÐ¼ĠÐ¸Ð·Ð²ÑĢÐ°ÑĤÐ¸ÑĤÑĮĠÐ¾Ð³Ð¾ÑĢĠÐ¿ÑĢÐ¾Ð¸Ð·Ð½ÐµÑģĠÑĤÐ²Ð¾ÑĢÐ¸Ð»Ð¾ÑģÑĮĠÑĪÑĤÑĥÑĢÐ¼Ð°ĠÐ±ÑĭÐ»Ð¸ĠÐ¾ÑģÑĤÐ°ÑĤÐºÐ¸ÐµÐ½Ð½ÑĭÐµĠÑĢÐ°Ð±Ð¾ÑĤÐ¾Ð¹ĠÐ¿Ð¾Ð´Ð½Ð¸Ð¼Ð°Ð»ÑģÑıĠÐºÑĢÑĭÐ»ÑĮÑĨÐ¾ÐŃÐºĠÐŀÐ´Ð½Ð°ĠÑģÐ²Ð¾Ð±Ð¾Ð´ĠÐ¼ÐµÑĤÐ°Ð»Ð¸ÐµÐ¿Ð°ĠÐ¿Ð¾Ð·Ð°Ð¿ÑĢÐ¾ÑĪĠÐ´ÑĳÑĢĠÐĳÐ¸Ð±Ð»Ð¸Ð¸ÐµÐ½ÐµÐ»ÑıÑīÐµÐµÑģÑıĠÐ²ÑĭĠÐ²ÑģÐµÑħÐĵÐ¾ÑģÑĥÐ´Ð°ÑĢÑĮĠÐ¸ĠÑģÐ¾Ð¾Ð±ÑĢÐ°Ð¶ÐµÐ½Ð¸ÑıÐ³Ð°ÐµÑĤÑģÑıĠÐ²ÑĭÐ´Ð°ÑĪÑĮĠÐ´Ð°Ð¼ĠÐ²ÑĭÑħÐ¾Ð´ÑıÑĤĠÐºÐ¾Ð·ĠÑģÐ¸Ð½Ð¸Ð¼ĠÐľÐ¸ÑħÐ°Ð¹Ð»Ð¾ĠÐ¿ÑĢÐ¾Ð´ÐµÐ»Ð°Ð»ĠÐºÐ°Ð¶Ð´Ð¾Ð¼ĠÑģÐ¿ÑĢÐ°Ð²Ð¸ÑĤÑĮÑģÑıĠÑĤÐ°ÑĤÐ°ÑĢÐ°Ð¼Ð¸ĠÐ±ÑĢÐµÐ²Ð½Ð¾ĠÑĤÑĢÐµÑĤÑĮÐµÐ¹ĠÐľÐ¸Ð»ÐºÑĥĠÑĪÐ¸ÑĢÐ¾ÐºÐ¾Ð³Ð¾ĠÐ¾ÑĤÑħÐ¾Ð´Ð¸ÑĤÑĮĠÑģÑĤÑĢÐµÐ»ÑıÑĤÑĮĠÐ¾ÐºÑĢÐµÑģÑĤÐ½ÑĭÑħĠÐ³ÐµÑĢÐ¾Ð¹ĠÐ¸ĠÐ¿ÑĢÐ¾ÑĪÐµÐ´ĠÐŀÐºÐ¾Ð»ĠÐ±Ð»ÐµÐ´ĠÐ½ÐµÐ¶Ð¸Ð²Ð°ÑıĠÐ½ÐµÐ½Ð°Ð³Ð»ÑıÐ´ĠÐ¼ÐµÐ»ÐºÐ¾ÑĤÐ°ĠÐ·Ð°ÐµÐ·Ð¶Ð°Ð»Ð¸ĠÐ½ÐµÐ²ÐµÑĢÐ¾ÑıÑĤÐ½Ð¾ĠÑģÐ¾Ð¾Ð±ÑīÐ¸Ð»Ð°ĠÑĩÐ¸ÑģÑĤÐ¾ĠÑģÐºÐ°Ð·ÐºÐµĠÐ¿Ð¾Ð´ÑģÑĤÑĥÐ¿ĠÑĢÐµÑĪÐ¸Ð»Ð¸ÑģÑĮĠÐĳÐ»Ð°Ð³Ð¾Ð´Ð°ÑĢÑıĠÐ¡ÐµÑĢÑĳÐ¶ĠÐ½ÐµÑĩÐ°ĠÐ²ĠÐ¿Ð¾Ð´ÑĩÐ¸Ð½Ð¸ÑĤÑĮÑģÑıÑĥÑģÑģÐ¸ÑıĠÐ´Ð²Ð¸Ð¶ÐµÐ½Ð¸ÑıÐ¼Ð¸ĠÐ´ÐµÑĢÐµÐ²Ð°ĠÐºÐ¾ÑĤÐ¾ÑĢÐ¾ÐµĠÐ²ÐµÑĩÐµÑĢÐ¾Ð¼ĠÐ¸Ð·Ð¼ÐµÐ½Ð¸Ð²ÑĪÐ¸Ð¹ÑģÑıĠÐ¾Ð¿ÑĭÑĤÐ½ÑĭÐ¹Ð°Ð²ÑĪÐµÐµÑģÑıĠÐ·Ð²ÑĳÐ·ĠÐ´Ð¾ÑģÐ¿ÐµÑħÐ¾Ð²ĠÐ²ĠÐ½Ð°ÑħÐ¾Ð´Ð¸Ð²ÑĪÐ¸Ð¼ÑģÑıĠÐ³Ð¾ÑģÑĥÐ´Ð°ÑĢÐµÐ²ĠÐ·Ð°Ð´Ð°Ð²Ð¸Ð»Ð¸ĠÐ¿Ð¾ÑĤÑĢÐ°Ð²ÑĥĠÐ¼ÐµÑģÑĤÐ½ÑĭÑħĠÐķÐ´Ð¸Ð½ĠÐ¿ÑĢÐ¾ÑĩÐµÐµĠÐ±Ð°Ð·Ð°ÑĢĠÐ¿Ð¾ÑģÐ»ÐµÐ´Ð¾Ð²Ð°Ð²Ð¿Ð°Ð¼Ð¸ĠÐ¿ÑĢÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð½Ð¾Ð¹ĠÐ¥ÐµĠÑĢÐµÐ·Ð²Ð¾ÑģÑĤÐ¸ĠÐłÐ¾Ð¼Ð°Ð½ÑĭÑĩĠÑģÑĤÑĢÐ°Ð¶ĠÐ¿Ð¾Ð¼ÐµÑĢÐ½Ð¾ÐµĠÐ¡ÑĥÐ·Ð´Ð°Ð»ÑĮĠÐ¿ÑĢÐ¾Ð·Ð²ÑĥÑĩÐ°Ð»ĠÑĢÐ°ÑģÑĪÐ¸ÑĢĠÐ¾ÑģÑĤÐ°Ð½ÑĮÑģÑıĠÐ»Ð°Ð³ÐµÑĢÑĮĠÑĤÐ²Ð¾ÑĢÐ¸ÑĤÑģÑıĠÐĿÐ°Ð´ĠÐ¿Ð¾Ð²ÐµÐ´ÐµÐ½Ð¸ÑİĠÑģÐ»ÐµÑĤÐµÐ»Ð°ĠÑĥÑģÐ°Ð´Ð¸ÑĤÑĮĠÐļÐŀÐµÑģÑĤÐ²ÐµÐ½Ð½ÑĭÐµĠÐ¾Ð±Ð¾Ð¸Ð¼ĠÑģÐ¾Ð·Ð½Ð°Ð½Ð¸ÐµĠÐĶÐ¾Ð»Ð¶Ð½Ð¾Ð°Ð´Ð°Ð¼Ð¸ĠÐ¿Ð¾Ð´Ð¾Ð·ÑĢÐ¸ÑĤÐµÐ»ÑĮÐ½Ð¾Ð¹ĠÐ²Ð¾ÑĤÐºÐ½ÑĥÐ»ÑģÑĤÐºÐ¸ÑħĠÐ²Ð¾ÑģÐ¿Ð¾Ð»ÑĮÐ·ĠÐ½Ð°ÑĩÐ¸Ð½Ð°ÐµÑĤÑģÑıÐ³ÑĪÐ¸ÑģÑĮÐ¾ÑģÑĮĠÐ·Ð°Ð¿Ð°ÑģÑĭĠÑĩÑĤÐ¾ĠÑĤÐ°ÐºÑĥÑİĠÑģÑĤÑĢÐ¾Ð¸ÑĤÐµÐ»ÑĮĠÐ¾ÑĤÐ²ÐµÑĤÑĮĠÐ·Ð°ÑīÐ¸ÑĤÐµĠÐ¾Ð³Ð½ÐµĠÐĳÑĭÑģÑĤÑĢÐµÐµĠÐ°ÑĢÐ³ÑĥÐ¼ÐµÐ½ÑĤĠÐ´ÑĢÑĥÐ³Ð¸Ð¼ĠÐ¿Ð¾Ð»Ð°Ð´Ð¸Ð»ĠÐ½Ð°ĠÑĢÐµÐ·Ð¾Ð½Ð½Ð¾ĠÐĴÐ¸Ð´Ð¸Ð¼Ð¾ĠÐ²Ð·Ð±ÐµÑģĠÐĴÐ¾ÑĤĠÐ³Ð¾ÑĢÐ°ÑħĠÐ¿Ð¾ÑıÐ²Ð»ÐµÐ½Ð¸ÑıĠÑĥÐºÑĢÐ°ÑĪĠÐ¿Ð¾Ð¹Ð´ÑĳÑĪÑĮĠÐĿÐ°Ð¹Ð´ÑĳÑĪÑĮĠÐ½ÐµÐ½Ð°Ð²Ð¸ÑģÑĤÑĮĠÑĪÐµÐ²ÐµÐ»ÑĮĠÐ¿ÑĢÐ¾Ð¸ÑģÑħÐ¾Ð´ÑıÑīÐµÐµĠÐ¿ÐµÑĢÐµÐ²ÐµÑĢĠÐ¿ÑĢÐ¾Ð´Ð¾Ð»Ð¶Ð°ÑİĠÐºÐ°ÑĩÐµÑģÑĤÐ²ÐµĠÐ½Ð¾Ð¶ĠÐ¸Ð·Ð¾ĠÐŁÑĢÐ¸ÐºĠÐĳÐ¸Ð±Ð»Ð¸Ð¸ĠÐ½ÐµÑģÑĩÐ°ÑģÑĤÐ½Ð¾Ð¹ĠÐĿÐ¾Ð²Ð³Ð¾ÑĢÐ¾Ð´ĠÐĿÐ¾ÑĩÑĮĠÑĢÐ°ÑģÑģÐµÑıÐ»Ð¸ÑģÑĮĠÐ¾Ð±ÑīÐ¸Ð¹ĠÐ¡ÑĥÐ·Ð´Ð°Ð»ĠÐ¡Ð¾Ð²ÑģÐµÐ¼ĠÐ²ÐµÑīÑĮÐ¸Ð½Ð¾Ð³Ð´Ð°ÐºÐ¾Ð¼ÑĥĠÐ¿Ð¾ÑģÑĤÐ°ÑĢÐ°Ð¹ÑģÑıÐ¸ÑĤÑĮÑģÑıĠÐ¾ÑĤÑģÑĤÑĥÐ¿Ð¸Ð»Ð¸ĠÑģÐ¶Ð°Ð»ĠÑĪÐµÑĢÑģÑĤÑıĠÐ´Ð¾Ð±ÐµÑĢÑĳÑĤÑģÑıĠÑĢÑĤÑĥĠÐ¿ÑĢÐ¾ÑĩÐµÐµĠÐ·Ð°Ð¿ÐµÑĩÐ°ÑĤĠÑģÐ´ÐµÑĢÐ¶Ð¸Ð²Ð°ÑĤÑĮĠÑģÐºÐ¾Ð¿ÐµÐ»ÐµÑĥÑĩÐ¸ÑĤĠÐ¾ÑĤÑĢÑıÐ´ÐµĠÑģÐµÐ¼ĠÑıÐ»ÑħÑįÐ´ĠÐ¿ÐµÑĢÐµÐ¿ÑĢÐ°Ð²ÐµĠÐ·Ð°Ð´Ð½Ð¸ÑħĠÑĤÐµĠÐ¸ĠÑĢÑĥÑģÑģÐºÐ¸ÑħĠÐ¿ÑĥÑĤÐ°Ð½ĠÐ¼Ð°Ð³Ð¾Ð¼ÐµÑĤÐ°Ð½Ð¸Ð½ĠÐ½ÐµÑĩÐµÑģÑĤĠÐ¢Ð°ÑĤÐ¾Ð½ÑĮÐºÐ¾ĠÑģÐ¾Ð¶Ð¶ÑĳÐ½Ð½ÑĭÐ¹ĠÑĥÑĩÐµÐ½Ð¸ÐµĠÑĢÐ°Ð·Ð´Ð°Ð²ĠÐ½ÐµÐ¼Ð½Ð¾Ð³Ð¸ÑħĠÐ½Ð°Ð´ÑĥÐ¼Ð°Ð»ĠÐĿÐ°Ð´ĠÐ²Ð¾ÑģÑĤÐ¾ÐºÐ°ĠÑĢÐ°Ð·Ð³Ð¾Ð²Ð°ÑĢÐ¸Ð²Ð°ÐµÑĪÑĮĠÑīÐµÐ»Ð¸ĠÐ¼Ð¾Ð»ĠÐ¿Ð»ÑİÐ½ÑĥÐ»ĠÑĥÐ±ÐµÑĢÐµÐ³Ð»Ð¸ĠÐ¿ÑĢÐ¾Ð¿Ð°Ð´Ð¸ĠÐŁÐ¾ÑģÑĢÐµÐ´Ð¸Ð°Ð²Ð°Ð¹ÑģÑıĠÑĪÐµÐµĠÑĩÑĤÐ¾\n",
      "\n",
      "Generated text (BPE, Multi Layer):\n",
      "ОднаждыĠÐĹÐ½Ð°ÑĩĠÐ»ÑİÐ´ÑĥĠÐ³Ð¾ÑĢÐ°ĠÐļÐ°ÐºÐ¾Ð²ĠÐłÐ¾Ð¼Ð°Ð½Ð¾Ð²Ð¸ÑĩÑĥĠÐ¢Ð°ÐºĠÐ§Ð¸ÑĤÑĢÐ°Ð´ÑĢÐ¸Ð²Ð°ÐľÐ¾Ð¹ÑħÐ¾Ð¼ĠÐ´Ð¾Ð±ÑĢÐ¾Ð²Ð¾Ð»ÑĮÑĨÐµÐ²ĠÐ¿ÑĢÐµÑĢÐ²Ð°Ð»ĠÐºÑĢÐ°ÑģÐ¾ÑĤÑĥÐŃÑĤÐ¾ĠÐ´Ð¾ĠÐ²ÐµÑĢÐ½ÑĳÐ¼ÑģÑıĠÐ²ÑĢÐ°Ð¶ÐµÑģÐºĠÐĿÐµÑĥÑĤÐµÑĪÐ½Ð°ÑıĠÐºÑĢÐµÑģÑĤÑĭÐµÐ½ÑĨÐµÐ²ĠÐŁÐ¾ÑĩÑĥÐ²ÑģÑĤÐ²Ð¾Ð²Ð°Ð²ĠÐ®ÑĢÑĮÐµÐ²Ð¸ÑĩĠÐ¨ÐµÐ¿ÑĤĠÐ½Ð°Ð¿Ð¾Ð¼Ð½ĠÐĴÐ¾Ð¸ÑĤÐµÐ»ÑĮĠÐ¿ÑĢÐ¾Ð¸Ð·Ð½Ð¾ÑģÐ¸ÑĤÑĮĠÐ½Ð°ĠÐ¾Ð±Ð¾ÑĢÐ²Ð°Ð½ÑĨÑĭĠÑģÐ²Ð¸Ð´ÐµÑĤÐµÐ»ÑĮÑģÑĤÐ²Ð¾Ð²Ð°Ð»Ð¸ĠÐ¿Ð¾Ð³Ð¾ĠÐĲÐ±ĠÐ¿Ð¾Ð»ÑĥÑĩÐ¸Ð»Ð¾ÑģÑĮÐµÐµĠÐĳÐ¾Ð³ĠÐŀÑģÐ¾Ð±ÐµÐ½Ð½Ð¾ĠÐ·Ð½Ð°Ð¼ÐµÐ½Ð¸ÑĤÑĭÐ¼ĠÑĥÑģÑĤÑĢÐ°ÑģÐ»ÑĥÐ³Ð°ĠÐ¾Ð±Ð¾ÑĢÐ²Ð°Ð»ĠÐ²ÑĢÐ°Ð³ĠÐĺÐ¿Ð°ÑĤÐ¸Ð¹ĠÑĤÑĭÑģÑıÑĩĠÐ¼Ð½ÐµÐ½Ð¸Ð¸ĠÐ¿ÑĢÐ¸Ð²ÐµÐ»Ð¸Ð°ÑĤÐµÐ»ÑĮĠÐ²Ð·Ð¾ÑĪÑĳÐ»ĠÐļÐ°ÐºÐ¾Ð¹ĠÐ§Ð¸ÑĤÑĢÐ°Ð´ÑĢÐ¸Ð²ÐµĠÐ¼Ð¸Ð³Ð¾Ð¼ĠÐĿÐµÐ¼ÐµÐ´Ð»ÐµÐ½Ð½Ð¾ĠÐľÐ°Ð»Ð¾ĠÐĶÑĢÐ¸Ð²ĠÐ¶ÑĥÑĤÐºÐ¾ĠÐ¾ÑĢÑĥÐ¶Ð¸ÐµĠÐ´Ð¾Ð³Ð¾Ð²Ð¾ÑĢĠÑĤÐ¾Ð³Ð´Ð°ĠÐ´ÐµÐ»Ð¾ĠÐ»Ð¾ÐºĠÐ´Ð¾ÑģÐ°Ð´Ð»Ð¸Ð²Ð¾ÑĤÐµÑĩĠÐ¿Ð¾Ð±ÑĭĠÐ¨Ð¼ÑĥÐ»ÑĮÐľÐ¾Ð¶Ð½Ð¾ĠÐ¸Ð·Ð±Ð°Ð²Ð¸ÑĤÑĮÑģÑıÐ½Ð¾Ð¼ÑĥĠÐłÐ°Ð·Ð¾ÑĪÐ»Ð¸ÑģÑĮĠÐ·ÑıÐ±ĠÐ¿Ð¾Ð¿Ð°Ð»Ð¸Ð½Ð¾Ð³Ð¾ĠÑģÑĭÐ½ÑĥÐ¸ÑıĠÐ¾ÑĤÐºÑĢÑĭÐ»Ð¾ÑģÑĮĠÐŀÑĤÐµÑĨĠÐ¿ÐµÑĢÐµÐ´ÐµÐ»ĠÐļÐ¾Ð»Ð´ÑĥĠÐ¼Ð°ÑģÐ»Ð¾ĠÐ½Ð°ÑĨÐµÐ¿Ð¸ÑĤÑĮĠÐ¥Ð¸ÑĤÐµÑĢĠÐ¼ÐµÑĢÐ·Ð¾ÑģÑĤÑĮÑĥÑİÑīÐµĠÐĵÐ¾ÑģÑĥÐ´Ð°ÑĢÑİĠÐ¾Ð²Ð»Ð°Ð´ÐµÐ²Ð°Ð»Ð¾ĠÐ»ÑİÐ±Ð¾Ð¿ÑĭÑĤÐ½ÑĭÐ¼ĠÐļÐ½ÑıĠÐ¿ÐµÑĢÐµÐ´Ð°ÑĤÑĮ,ĠÐĸÐ¸Ð²Ð¾ĠÐ¿Ð¾Ð»Ð°Ð³Ð°ÑİĠÐĳÐµÐ½Ð´ÑĢÐ¸ĠÐĴÐ¸Ð´ÐµÐ»ĠÐ´Ð¾Ð²Ð¾Ð»ÑĮÐ½Ð¾ĠÑĥÑĤÐ¾Ð¼ĠÐºÐ»Ð¸ÑĩĠÐ¿ÑĢÐ¾ÑģÐ¸ÑıÐ»ĠÑģÐ²ÑıÑĤÐ°ÑıĠÐŁÑĢÐ¸Ð·Ð½Ð°Ñİ!ĠÐľÐ½ÐµĠÐ£Ð´Ð¸Ð²ĠÐĿÐ¾Ð²Ð³Ð¾ÑĢÐ¾Ð´ÑģÐºÐ¸Ð¹ĠÐ¸Ð»Ð¸ĠÐŁÐ¾ÑĩÑĳÑĤÐ½Ð¾ĠÑģÐºÐ¾Ð²ĠÐ±ÐµÐ´Ð½Ð¾ÑĤÑĭĠÑģÑĤÐ¸ÑħÐ¸Ð¹Ð½Ð¾ĠÐŁÐ¾Ð¿ĠÐºÐ¾Ð¶Ð¸ÑĨÐµÐ¹ĠÐ¿Ð¾ÑģÐ»Ð°Ð½ĠÐ¿ÑĢÐ¾ÑģÑĤÑĭÐ¼ĠÑĩÐ°ÑīÐµĠÐŁÑĢÐ¸Ð·Ð½Ð°ÑĤÑĮÑģÑıÐµÐ½ÐµÐ»Ð¸ÑĢÐ°ÑİÑĤĠÐ¿Ð¾Ð´ÑĢÐ¾Ð±Ð½Ð¾ÑģÑĤÐ¸ĠÐ¼ÐµÑĢÑĤĠÐĶÑĢÑĥÐ³Ð¸ÐµĠÐ·Ð½Ð°ÑĩÐ¸Ð»Ð¾ĠÐ¡ĠÐŀÐ±ÐµĠÐ½ÐµÐ¶Ð½ÑĭÐ¹ĠÐ²Ð¸Ð´Ð½ÐµÐ²ĠÑģÑĥÐ´Ð¾ÑĢÐ¾Ð¶Ð½Ð¾ĠÐŁÑĢÐ°Ð²Ð´Ð°ĠÐ¿ÑĢÐ¸Ð½Ð¾ÑģÑĢÐ°Ð¼ĠÐ¶Ð¸Ð²ÑĳÑĤÐµÑĳÑĤÐµĠÑģÐµÐ³Ð¾Ð´Ð½ÑıÑĪÐ½ÑıÑıĠÐĲĠÐļĠÐŁÑĢÐ¸ÑĪĠÑĢÑĭÐ¶ÐµÐ²ĠÐĿÐµÐ³ĠÐĵÐ¼ÑĥÐ¹ÑģÑıĠÐ¸Ð·Ð±ÐµÐ¶Ð°ÑĤÑĮĠÐĽÐµÐ¶Ð°ÑīĠÐ¿Ð¾ÑĩÐµÑģÑĤÐ¸ĠÑĤÐ¾Ð¿Ð¾ÑĩÐ¸ĠÐ¿ÑĢÐ¾ÑģÑĤÐ¾Ð³Ð¾ĠÑĥÑħÐ¼ÑĭĠÐ¡Ð»Ð¾Ð²ĠÐļÐ¸ÐµÐ²ÑģÐºÐ¸Ð¹ĠÐĿÐµĠÐ¡ÑĤÑĥÐ´ÑĳÐ½Ð°ÑıĠÐĿÐµÑĩÐµÐ³Ð¾ĠÐ¾ÑĤÐ¿ÑĥÑģÑĤÐ¸ÑĤÑĮĠÐĴÐ¾ÐºÑĢÑĥÐ³ĠÐ¿Ð¾Ð²ÑĤÐ¾ÑĢÑıÑĤÑĮĠÐ½Ð°ÑĢÐ¾Ð´Ñĥ,ĠÐĺĠÐŁÐ¾ĠÐ±ÐµÐ·Ð²ÐºÑĥÑģĠÐ·Ð°Ð¼ÐµÐ»ÑĮÐºĠÑĩÑĮÑıĠÐĹÐ°Ð¼ÐµÑĤÑĮÐ½Ð¸ÐºÐ°ĠÑĩÑĥÐ¶Ð°ÐºÐ¾Ð²ĠÑģÐ»ÑĥÐ³ĠÑĦÑĭÑĢÐºÐ½ÑĥÐ»ĠÐ¿Ð¾Ð³Ð¸Ð±ĠÐ¿Ð¾ÑģÐ»ÑĥÑĪĠÐ¼Ð½Ð¸Ð¼Ð¾Ð³Ð¾Ð¾ÑĩÐºÐ°Ð¼Ð¸ĠÐ°ÑĢÐ¼Ð°Ð´Ð°ĠÐ¿ÑĢÐ¾Ð¸ÑģÑħÐ¾Ð´Ð¸Ð»Ð¾Ð½Ð¾Ð³Ð¾ĠÐĿÐµÑģÐºÐ¾Ð»ÑĮĠÐ¥Ð¾Ð»Ð¾Ð´Ð½Ð¾ĠÐ¡ÑĥÐ¿Ð½Ð°ÑıÐ³Ð¾ÑĤĠÑĦÐ°Ð»ÑĮÑĪÐ¸Ð²Ð°ÑıĠÐ¿Ð¾ÑĤÐ¾ÐºÐ°Ð¼Ð¸ĠÐĿÑĭÐ½ÑĩÐµĠÐĿÐ¸ÐºÑĥÐ´Ð°Ð»Ð¸ĠÐ½Ð°ÐºÐ¾Ð½ÐµÑĨĠÐ¡ÑħÐ²Ð°ÑĤĠÐĶÐ¾Ð»Ð³Ð¸Ð¹ĠÐºÐ°ÐºÑĩÐ°ÑģÑĤĠÑīÑĳĠÐ¶Ð°Ð»ÐºÐ¾ĠÐĶÑĢÐ¸Ð²ĠÐ²ÐµÐ»Ð¸ÐºÐ°ÑıĠÑĥÐ±ÐµÐ´Ð¸Ð»ĠÐŀÐ´Ð½Ð¾Ð¹ĠÑĨÐµÐ»Ð¸Ð»Ð°ÑģÑĮĠÐ²Ð¾Ð»Ð½Ð¾Ð²Ð°Ð»ÑģÑıĠÐ¾ÑĤÐ²Ð»ÐµÐºÐ°ÑĤÑĮĠÐºÐ¾Ð»Ð´Ð¾Ð²ÑģÐºÐ°ÑıĠÐ·ÑıÑĤÑĮĠÐĶÐ°Ð½Ð¸Ð»ÐºÐ¸ĠÐľÐ¾Ð»ĠÑĤÑĥÐ¼Ð°Ð½Ð½ÑĭÐµĠÐĿĠÐ¼ÐµÐ½ÑıĠÐŃÑĤÐ¾ĠÐ¯ĠÐŀÐ´Ð½Ð°ÐºÐ¾ĠÐ½ÐµÐ²ÐµÑģÐµÐ»Ð¾ĠÑģÑĥÐ´Ð¾ÑĢÐ¾Ð¶Ð½Ð¾ĠÐĵÐ´ÐµĠÐ¿Ð¾ĠÐĿÐ°Ð·ÑĭÐ²Ð°Ð¹ĠÐ¿ÐµÑĢÐµÐ¹Ð´ÑıĠĠĠĠĠÐĶÐ°Ð½Ð¸Ð»Ð°ĠÐ´Ð°ĠÐŁÐµÐ¼ÐµÐ½ÑħÐ°ÑĤĠÑģÐ´ÐµÑĢÐ¶Ð°Ð½Ð½ÑĭÐ¹ĠÐ²Ð¿Ð¾Ð»ÑĥÑħÐ°ĠÐ´Ð¾ÑĢĠÐ¾Ð±Ð»Ð¸Ð»Ð¸ĠÐ¿Ð¾Ð¼Ð¸Ð¼Ð¾ÑĨÐµÑĢĠÐĹÐ°ÑģÐ½ÑĥÐ»ĠÐ¸Ð»Ð¸ĠÐŁÐ¾Ð»Ð¾Ð¶ÐµÐ½Ð¸ÐµĠÑģÐ¾Ð¾Ð±ÑīÐ°ÐµÑĤĠÑģÐµÐ³Ð¾Ð´Ð½ÑıÑĪÐ½ÐµÐ¹Ð¾ÑĤÐ½Ð¾ĠÐļÐ°Ð¶Ð´ÑĭÐ¹ĠÐ¿ÑĢÐ¾Ð´Ð¾Ð»Ð¶Ð¸Ð¼ĠÑĤÐµÐ¼ÑĥĠÐ²ÑĭÐ·ÑĭÐ²Ð°Ð»Ð¾ĠĠĠĠĠÐļÐ°ÑĢÑģÐ¸Ð´Ð°ÑĢĠÑĥÐ´Ð°ÑĢÐ¸Ð»ĠÐ´ÑĢÑĥÐ³Ð°ĠÐ²ĠÐ¿ÑĢÐ¸Ð½ÑĥÐ´ĠÐ¿Ð¾Ð¼Ð¾Ð³ÑĥÐµÐ´ÐµÐ²ÑĪÐµÐ³Ð¾ĠÑģÐ²ÐµÑĢÐºÐ½ÑĥÐ»Ð¸ÑĳÐ½Ð½Ð¾Ð³Ð¾ĠÐ¾Ð½ĠÐļÐ¾Ð»Ð´Ð¾Ð²ÑģÑĤÐ²Ð¾ĠÑģÐ¿ÐµÑĨÐ¸Ð°Ð»ÑĮÐ½Ð¾ĠÐ¾Ð±ÑĢÐ°ÑĤÐ½Ð¾?..ĠĠĠĠĠÐ½ÐµÐ¿Ð¾Ð½ÑıÑĤÐ½Ð¾ĠÐ´Ð¾ÑģÑĤÐ¾Ð¸Ð½ÑģÑĤÐ²Ð°ĠÑĢÐ¾Ð´Ð¾Ð²Ð½ÑĥÐ²ÑĪÑĥÑİÑģÑıĠÐ¸Ð·Ð±ÐµÐ¶Ð°ÑĤÑĮĠÑģÐ²ÐµÑĤÐ»ÐµÐµĠÐ¿Ð¾Ð¶Ð°ÑĢĠÐ½ÐµÑĥÐ´Ð°Ð²ÑĪÐµÐµÑģÑıĠÐ²Ð½ÑĥÑĤÑĢÐµÐ½Ð½Ð¸ÐµĠÑįÑĦÑĦÐµÐºÑĤÐ¸Ð²Ð¾ĠÐĴÐ¾ÑĤĠÐļÐ°ÑĢÑģÐ¸Ð´Ð°ÑĢĠÑĦÐ°Ð¼Ð¸Ð»ÑĮÑıĠÐ¡Ð´ÐµÑĢÐ¶ĠÐ¿ÑĢÐµÐ´Ð¿Ð¾ÑĩÑĳÐ»ĠÐĺÐ½ÑĤÐµÑĢÐµÑģÐ½Ð¾Ð½ÑĭÐµĠÐŀÐ±ÑĭÑĩÐ½Ð¾ĠÑĤÐ¾ÑĩÐ°ÑĤĠÐ¡Ð¾Ð±ĠÐ¡Ð¸Ð´ĠÐ¼Ð¾Ð»Ð½Ð¸ÑıÐ°Ð¹ÑĤÐµĠÐ½Ð°ĠÐ½ÐµÐ²Ð½ÑıÑĤĠÑĨÐµÐ»ĠÐ¾ÑĤÑĢÐ¾ÑģÐ¾Ð½ÑĮÐºÐ°Ð½Ð°ÑıĠÐ·ÑıÑĤÑĮÐ°Ð¹ÑĤÐµĠÐ½Ð°ĠÐ½ÐµÐ¾Ð±ÑĭÑĩÐ½Ð¾ÐµÐµÐ½Ġ\"ĠÐ¥Ð¸ÑĤÑĳÑĢĠÑĥÐ¶ĠÐ§ÑĤÐ¾ĠÐľÐ¸ÑħÐ°Ð¹Ð»Ð¾ĠÐĿÐµÐ¼ÐµÐ´Ð»ÐµÐ½Ð½Ð¾ĠÐĴÑĢÑıÐ´,ĠÐĽÑİÐ´Ð¸ĠÐ¼Ð¾Ð¼ÐµÐ½ÑĤÑĭĠÐ¿Ð¾ÑĤÐ°ÑģÐ¾Ð²ÐºÐ¸ĠÐłÐ¾Ð¼Ð³ÑĥÑĢÑĦÐ¾Ð¼ĠÐ½Ð°Ð´Ð¾ĠÑıÐŁÐ»ÑĭÐ²Ð°Ð²ÑĪÐ¸Ð¼Ð¸ĠÐ¿ÑĢÐ¾ÑĨÐµÐ´Ð¸Ð»ĠĠĠĠĠ\"ĠÐĵÐ¾ÑģÑĤÐµÐ¹ĠÐ¼Ð¾Ð»Ð¾Ð´ÐµÐ½ÑĮÐºÐ¾Ð¹Ð¼Ð¾Ð½ÐµĠÐ¾ÑĨÐµÐ½ĠÑģÐ²ÐµÑĤÐ»ÐµÐµĠÐ¿ÑĢÐµÐ´ÐµÐ»ÑĮÐ½Ð¾ĠÐĶÐ¾ÑģÑĤĠÐĵÐ¼ĠÑģÑĤÑĢÐ°Ð½ÑģÑĤÐ²Ð¾Ð²Ð°ÑĤÑĮĠÐļÐ°ÑĢÑģÐ¸Ð´Ð°ÑĢĠÐ¿Ð¾ÐºÑĥÑĪÐµÐ½Ð¸ÐµĠÐ¾ÐºÐ°Ð·Ð°Ð½Ð½ÑĥÑİĠÐ±ÑĢÐ¾ÑģÐ°ÑıÑģÑĮĠÐ²ÑĭÑģÐ¾ÑĩÐµĠÐ½ÐµÐ¾Ð±ÑĭÑĩÐ½ÑĭÑħÑĪÐ¸ÑħÐ°ÑĦĠÑĤÐ¸Ð¿ĠÐ¿Ð»Ð°Ð²ĠÐ¶Ð´Ð°Ð»Ð¸Ð°Ð»Ð¾ÑģÑĮĠÐ·Ð°ĠÐĹÐ´ÐµÑģÑĮĠÐļÐ¾Ð½ÐµÑĩÐ½Ð¾ÐµÐ½Ð¸ÑıÐ¼Ð¸ĠÑĪÑĳÐ¿Ð¾ÑĤÐ¾Ð¼ĠÐ¶ÐµĠÐĸÐ´Ð¸ĠÐ¸Ð»Ð¸ĠÐŁÐ¾ÑģÐºÐ¾Ð»ÑĮÐºÑĥĠÐĹÐ½Ð°ÐµÑĪÑĮĠÐ»ÑİÐ±Ð¾Ð¿ÑĭÑĤÐ½Ð¾ĠÑģÐ»ÐµÐ´Ð¸ĠÐ½Ð°ĠÐ²ÑĭÐ±ÐµÑĢĠÑĤÐ¸Ð¿ĠÐ·Ð°Ð²ÐµÑīÐ°Ð»ĠÐļÐ°ÑĢÑģÐ¸Ð´Ð°ÑĢÐ°ĠÐ½Ð°ĠÐ¿Ð¾Ð½Ð¸Ð¼Ð°ÐµÑĪÑĮĠÑĥÐ¿ÑĢÐ°Ð²Ð¸ÑĤÑĮÑģÑı:ĠÐ²Ð¾Ð½ĠÐºÐ¾Ð»Ð´ÑĥÐ½Ð¾Ð²ĠÐľÐ¸ÐºÑĥÐ»Ð°ĠÐŀÑĤÐ½ÑĭÐ½ÐµĠÐ½Ð¾ÑĢÐ¼Ð°Ð»ÑĮÐ½ÑĭÐµĠÐĶÐµÑģĠÐ³Ð½ÐµÐ²Ð°ĠÐŁÐ¾ÑģÐ¾Ð»ĠÑĩÑĤÐ¾Ð±ĠÐĶÑĥÐ¼Ð°ÑĤÑĮĠÐ§Ð¸ÑĤÑĢÐ°Ð´ÑĢÐ¸Ð²Ð°Ð°Ð²ÑĨÑĭĠÑĢÐ°ÑģÑĤÐµÑĢÑıÐ»ĠÐ¾Ð±Ð¶Ð¸Ð³ĠÐ±ÐµÑģÑĤÐ¸ÑıĠÐŁÐ»Ð¾ÑģÐºÐ¸Ð½ÑıĠÐ¿ÐµÑĢÐµÐ½ÑĳÑģÑģÑıĠÐłÐ°ÑģÐ¿Ð¾Ð»ĠÐĲÐ»ÑĮÐµÑĢÐ°Ð¼Ð¸ĠÐ¿Ð°ÑĢÐ½Ð¸ĠÐ¡Ð¾ÑģÐ»ĠÐ¿ÐµÑĢÐµÐºÑĢÐ¸ÐºĠÐ¡ÐºÑĥĠÐ±Ð¾Ð´ÑĢĠÐ´Ð¾ÑĪÐ»Ð¸ĠÑĥÐ±ÐµÐ¶Ð°Ð»ÐµÐ½Ð¸Ð¹ĠÐĹÐ´ÐµÑģÑĮĠÑĢÐµÐ·ÐºÐ¾ĠÐĵÐ´ÐµĠÐ½Ð°ÐºÐ¾Ð½ÐµÑĨĠÐ²Ð½Ð¾Ð²ÑĮĠÑģÑĤÑĭÑĩÐºÐ¸:ĠÐ²Ð¾Ð½ĠÐºÐ°ÐºĠÐĴÐ¸Ð´Ð¸Ð¼Ð¾ÑıÑİĠÐ¢Ð°ÐºĠÐ°ĠÐķÑģÐ»Ð¸ĠÐļÐ»Ð¾ÐºĠÐ½Ð°ÑĩÐ½Ð¸Ð¾ÐºĠÐºÐ°ÐºÐ¾Ð¹ĠÑıĠÐ§ÐµÐ³Ð¾ĠÐļÑģÑĤÐ°ÑĤÐ¸ĠÐ¿Ð¾Ð³Ð¸Ð±Ð¾Ð»ĠÐĿÐ°Ð´Ð¾ĠÐŀÐ´Ð½Ð¾ĠÐ¡Ð°Ð¼Ð¾ÐµĠÐļÐ¾Ð¹ĠÐĴÐ¾ÑĤĠÐŁÐµÐ¼ÐµÐ½ÑħÐ°ÑĤĠÐĹÐ°ÑĤÐµÐ¼ĠÐ¿ÑĢÐ¸Ð³Ð¾ÑĤÐ¾Ð²ĠÐ´Ð°Ð»Ð°ĠÐ§Ð¸ÑĤÑĢÐ°Ð´ÑĢÐ¸Ð²Ð°ĠÐ±Ð»Ð°Ð³Ð¾ÑģÐ»Ð¾Ð²ÐµÐ½Ð¸Ðµ\n"
     ]
    }
   ],
   "source": [
    "def generate_text_bpe(model, start_text, tokenizer_bpe, idx_to_token, length=400, temperature=1.0):\n",
    "    # Преобразование стартового текста в токены\n",
    "    input_seq = tokenizer_bpe.encode(start_text).ids\n",
    "    generated_text = start_text\n",
    "\n",
    "    for _ in range(length):\n",
    "        # Преобразование последовательности в numpy массив\n",
    "        x_pred = np.array([input_seq])\n",
    "\n",
    "        # Предсказание следующего токена\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        preds = np.asarray(preds).astype('float64')\n",
    "        preds = np.log(preds) / temperature\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "        next_index = np.random.choice(range(len(preds)), p=preds)\n",
    "        next_token = idx_to_token[next_index]\n",
    "\n",
    "        # Добавление предсказанного токена в результат\n",
    "        generated_text += tokenizer_bpe.decode([next_index])\n",
    "        input_seq.append(next_index)\n",
    "        input_seq = input_seq[1:]\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "# Создание словаря индексов токенов\n",
    "idx_to_token = {v: k for k, v in tokenizer_bpe.get_vocab().items()}\n",
    "\n",
    "start_text_bpe = \"Однажды\"\n",
    "\n",
    "# Генерация текста для однослойной модели\n",
    "print(\"Generated text (BPE, Single Layer):\")\n",
    "print(generate_text_bpe(model_bpe, start_text_bpe, tokenizer_bpe, idx_to_token))\n",
    "\n",
    "# Генерация текста для многослойной модели\n",
    "print(\"\\nGenerated text (BPE, Multi Layer):\")\n",
    "print(generate_text_bpe(model_multi_bpe, start_text_bpe, tokenizer_bpe, idx_to_token))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
